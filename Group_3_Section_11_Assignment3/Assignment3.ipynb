{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from neo4j import Query\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parent': ['root'], 'child': ['Node1'], 'relationshiptype': ['M']}\n",
      "{'root': {'children': [['Node1'], [[]]], 'ancestors': [[]], 'children_pattern': ['M', 'O']}, 'Node1': {'children': [[]], 'ancestors': [['root'], [[]]], 'children_pattern': ['Star', 'E']}}\n",
      "{'Node1': {'parent': {'M': 'root'}}}\n"
     ]
    }
   ],
   "source": [
    "# define the choice of children patterns.\n",
    "child_patterns = [['Star', 'E'], ['Star', 'R'], ['A', 'E'], ['A', 'R'], ['M', 'O'], ['O', 'E'], ['O', 'R']]\n",
    "\n",
    "# Initialize the datasets and the first two node for output\n",
    "root_pattern = random.choice(child_patterns)    # select a pattern for root\n",
    "root_1 = root_pattern[0]    # indicate the realtionshiptype for root to 1\n",
    "output_initial = {'parent':['root'], 'child':['Node1'], 'relationshiptype':[root_1]}\n",
    "\n",
    "# Define and initialize the nodes we can choose to start and end\n",
    "nodes_start_initial = {'root':{'children':[['Node1']], 'ancestors':[[]], 'children_pattern':root_pattern}}\n",
    "nodes_start_initial['Node1'] = {'children':[[]], 'ancestors':[['root']], 'children_pattern':random.choice(child_patterns)} # use the attribute of python shallow copy for ancestors, so that we can do change at same time\n",
    "nodes_end_initial = {'Node1':{'parent':{root_1:'root'}}}\n",
    "nodes_start_initial['Node1']['ancestors'].append(nodes_start_initial['root']['ancestors'])\n",
    "nodes_start_initial['root']['children'].append(nodes_start_initial['Node1']['children'])\n",
    "\n",
    "# nodes_start['root']['ancestors'][0].append(1) #check for the design\n",
    "print(output_initial)\n",
    "print(nodes_start_initial)\n",
    "print(nodes_end_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to delete node in nodes_end\n",
    "def delete_node_end(end_node:str, nodes_start:dict, nodes_end:dict) -> None:\n",
    "    if len(nodes_end[end_node]['parent']) == 2:\n",
    "        del nodes_end[end_node]\n",
    "    ## 'E', 'R' cannot point to a parent have 'M' relationship\n",
    "    if nodes_start[end_node]['children_pattern'] == ['M','O']:\n",
    "        del nodes_end[end_node]\n",
    "\n",
    "# delete_node_end('Node1', nodes_end_initial)\n",
    "\n",
    "# Define function to treat the list as string to get the ancestors and children\n",
    "def flatten_nested_list(nested_list):\n",
    "    flattened_str = str(nested_list).replace('[','').replace(']','').replace(\"'\",'').split(', ')\n",
    "    return [item for item in flattened_str if item]\n",
    "\n",
    "# Define function to get a node's nonancestors\n",
    "def get_nonancestor(start_node:str, nodes_start:dict,nodes_end:dict):\n",
    "    ancestors = flatten_nested_list(nodes_start[start_node]['ancestors'])\n",
    "    nonancestors = [item for item in list(nodes_end.keys()) if item not in ancestors+[start_node]+nodes_start[start_node]['children'][0]]\n",
    "    # print(ancestors+[start_node]+nodes_start[start_node]['children'][0],nonancestors)\n",
    "    return [ancestors,nonancestors]\n",
    "\n",
    "# Define function to get a node's nonchildren\n",
    "def get_nonchildren(start_node:str, nodes_start:dict, nodes_end:dict):\n",
    "    children = flatten_nested_list(nodes_start[start_node]['children'])\n",
    "    nonchildren = [item for item in list(nodes_end.keys()) if item not in children+[start_node]]\n",
    "    # print(children+[start_node],nonchildren)\n",
    "    return [children,nonchildren]\n",
    "\n",
    "# Define function to add relationship to the graph\n",
    "def add_relationship(nodes_start: dict, nodes_end: dict, output: dict, node_count, child_patterns = child_patterns):\n",
    "    start_node = random.choice(list(nodes_start.keys())) # select the start node\n",
    "    end_node_type = random.choice(['new','old'])    # select a type for end_node with probability 0.5\n",
    "\n",
    "    if  len(nodes_end) != 0:    # get the nonancestor list\n",
    "        end_node = random.choice(list(nodes_end.keys()))    # set a old nodes for the temp selected end_node\n",
    "        nonancestor = get_nonancestor(start_node,nodes_start, nodes_end)[1]  # get the nonancestors for temp selected end_node\n",
    "        # nonchildren = get_nonchildren(start_node, nodes_start, nodes_end)[1] # get non children\n",
    "\n",
    "    if len(nodes_end) == 0 or len(nonancestor) == 0 or nodes_start[start_node]['children_pattern'] == ['M', 'O']: # set the type to new when there's not a choice\n",
    "        end_node_type = 'new'\n",
    "\n",
    "    if end_node_type == 'old':   # update data if type = 'old'   \n",
    "        end_node = random.choice(nonancestor)   # choose the start node for this situation.\n",
    "        # print('old',start_node,end_node,nodes_start[start_node]) # code for check\n",
    "        node_pattern = nodes_start[start_node]['children_pattern'][1] # get the pattern for end_node\n",
    "        if nodes_start[start_node]['children'] == [[]]:\n",
    "            node_pattern = nodes_start[start_node]['children_pattern'][0] # avoid only E,R appears in this case       \n",
    "        \n",
    "        # updata nodes_end\n",
    "        nodes_end[end_node]['parent'][node_pattern] = start_node    # update nodes_end with new relationship\n",
    "        del nodes_end[end_node] # delete the nodes that cannot be selected anymore\n",
    "        \n",
    "        # updata output\n",
    "        output['parent'].append(start_node)\n",
    "        output['child'].append(end_node)\n",
    "        output['relationshiptype'].append(node_pattern)\n",
    "        \n",
    "        # updata nodes_start\n",
    "        nodes_start[start_node]['children'][0].append(end_node)\n",
    "        nodes_start[start_node]['children'].append(nodes_start[end_node]['children'])\n",
    "        nodes_start[end_node]['ancestors'][0].append(start_node)\n",
    "        nodes_start[end_node]['ancestors'].append(nodes_start[start_node]['ancestors'])\n",
    "\n",
    "    else:   # update data if type = 'new' \n",
    "        # print('new', start_node,nodes_start[start_node])  # code for check\n",
    "        node_pattern = nodes_start[start_node]['children_pattern'][0]   # should not get a 'E' or 'R'relaitonship with new node,incase it just end with it finally\n",
    "        if nodes_start[start_node]['children_pattern'] == ['M','O']:\n",
    "            node_pattern = random.choice(['M','O'])\n",
    "        end_node = 'Node' + str(node_count) # Define the name for new node\n",
    "        node_count += 1 # update node_count\n",
    "\n",
    "        # update output\n",
    "        output['parent'].append(start_node)\n",
    "        output['child'].append(end_node)\n",
    "        output['relationshiptype'].append(node_pattern)\n",
    "\n",
    "        # update nodes_end\n",
    "        nodes_end[end_node] = {'parent':{}} # initialize node_end for new node\n",
    "        nodes_end[end_node]['parent'][node_pattern] = start_node    # update nodes_end with new relationship\n",
    "        \n",
    "        # update nodes_start\n",
    "        new_node_pattern = random.choice(child_patterns) # select a pattern for new node\n",
    "        # print(new_node_pattern) # code for check\n",
    "        nodes_start[end_node] = {'children':[[]], 'ancestors':[[]], 'children_pattern':new_node_pattern} # initialize node_end for new node\n",
    "        nodes_start[start_node]['children'][0].append(end_node)\n",
    "        nodes_start[start_node]['children'] = nodes_start[start_node]['children'] + nodes_start[end_node]['children']\n",
    "        nodes_start[end_node]['ancestors'][0].append(start_node)\n",
    "        # print(nodes_start[end_node]['ancestors'][-1])\n",
    "        nodes_start[end_node]['ancestors'].append(nodes_start[start_node]['ancestors'])\n",
    "        delete_node_end(end_node,nodes_start,nodes_end) # delete the nodes that cannot be selected anymore\n",
    "\n",
    "    return [nodes_start, nodes_end, output, node_count]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# Define how many rows we want\n",
    "num_rows1 = 500 - 1\n",
    "num_rows2 = 1000 - 1\n",
    "num_rows3 = 10000 - 1\n",
    "num_rows4 = 20000 - 1\n",
    "\n",
    "# Initialize the parameters\n",
    "output,nodes_start,nodes_end = copy.deepcopy(output_initial),copy.deepcopy(nodes_start_initial),copy.deepcopy(nodes_end_initial)\n",
    "node_count = len(nodes_start)\n",
    "# print(output,'\\n',nodes_start,'\\n',nodes_end,'\\n',node_count) #code for check initial\n",
    "# run and get output with size 500\n",
    "for _ in range(num_rows1):\n",
    "    nodes_start, nodes_end, output, node_count = add_relationship(nodes_start, nodes_end, output, node_count, child_patterns)\n",
    "output_500 = output\n",
    "\n",
    "# run with size 1k\n",
    "output,nodes_start,nodes_end = copy.deepcopy(output_initial),copy.deepcopy(nodes_start_initial),copy.deepcopy(nodes_end_initial)\n",
    "node_count = len(nodes_start)\n",
    "# print(output,'\\n',nodes_start,'\\n',nodes_end,'\\n',node_count) # code for check initial\n",
    "for _ in range(num_rows2):\n",
    "    nodes_start, nodes_end, output, node_count = add_relationship(nodes_start, nodes_end, output, node_count, child_patterns)\n",
    "output_1k = output\n",
    "\n",
    "# run with size 10k\n",
    "output,nodes_start,nodes_end = copy.deepcopy(output_initial),copy.deepcopy(nodes_start_initial),copy.deepcopy(nodes_end_initial)\n",
    "node_count = len(nodes_start)\n",
    "for _ in range(num_rows3):\n",
    "    nodes_start, nodes_end, output, node_count = add_relationship(nodes_start, nodes_end, output, node_count, child_patterns)\n",
    "output_10k = output\n",
    "\n",
    "# run with size 20k\n",
    "output,nodes_start,nodes_end = copy.deepcopy(output_initial),copy.deepcopy(nodes_start_initial),copy.deepcopy(nodes_end_initial)\n",
    "node_count = len(nodes_start)\n",
    "for _ in range(num_rows4):\n",
    "    nodes_start, nodes_end, output, node_count = add_relationship(nodes_start, nodes_end, output, node_count, child_patterns)\n",
    "output_20k = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_500 = pd.DataFrame(output_500)\n",
    "data_1k = pd.DataFrame(output_1k)\n",
    "data_10k = pd.DataFrame(output_10k)\n",
    "data_20k = pd.DataFrame(output_20k)\n",
    "data_500.to_csv(\"data_500.csv\", index=False)\n",
    "data_1k.to_csv(\"data_1k.csv\", index=False)\n",
    "data_10k.to_csv(\"data_10k.csv\", index=False)\n",
    "data_20k.to_csv(\"data_20k.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2]] [[3, 4], [[1, 2]]] [[5, 6], [[3, 4], [[1, 2]]]]\n",
      "[[1, 2, 5]] [[3, 4], [[1, 2, 5]]] [[5, 6], [[3, 4], [[1, 2, 5]]]]\n"
     ]
    }
   ],
   "source": [
    "# # illustration of the code\n",
    "# def flatten_nested_list(nested_list):\n",
    "#     flattened_str = str(nested_list).replace('[','').replace(']','').replace(\"'\",'').split(', ')\n",
    "#     return [item for item in flattened_str if item]\n",
    "\n",
    "# nested_list = [['Node1'], [['root', 'Node1'], [[]], [['root', 'Node1'], [[]], [['root'], [[]]]]]]\n",
    "\n",
    "# result = flatten_nested_list(nested_list)\n",
    "# print(result)\n",
    "\n",
    "# A = [[1,2]]\n",
    "# B = [[3,4]]\n",
    "# C = [[5,6]]\n",
    "# # for i in range(len(B[0])):\n",
    "# C.append(B)\n",
    "# B.append(A)\n",
    "# print(A,B,C)\n",
    "# A[0].append(5)\n",
    "# print(A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please put the csv file to the neo4j database folder first!!!\n",
    "\n",
    "#Establishing a connection to the Neo4j database\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "def load_session(database_name, filepath)->None:\n",
    "    #Using the connection to run a session\n",
    "    with driver.session(database=database_name) as session:\n",
    "    #Query to load a CSV file (attached on BB). \n",
    "        #You can break the long Cypher query into multiple lines in Python using triple-quoted stringse:\n",
    "        loadQuery = f\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM '{filepath}' AS line\n",
    "        MERGE (n:Node {{name: line.child}})\n",
    "        MERGE (m:Node {{name: line.parent}})\n",
    "        MERGE (n)<-[r:isParentOf {{rType: line.relationshiptype}}]-(m)\n",
    "        \"\"\"\n",
    "        #Record the start time before executing the query to load data\n",
    "        loadStartTime = time.time()\n",
    "\n",
    "        #Execute the query to load data\n",
    "        LoadResult = session.run(loadQuery)\n",
    "\n",
    "        #Record the end time after executing the query to load data\n",
    "        LoadEndTime = time.time()\n",
    "\n",
    "        #Calculate and print the time taken to execute the query for loading data\n",
    "        print(\"\\n\\nThe execution time to load the CSV file to Neo4j is :\", LoadEndTime - loadStartTime, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The execution time to load the CSV file to Neo4j is : 237.70694518089294 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_session('assign3data500','file:///data_500.csv')\n",
    "load_session('assign3data1k','file:///data_1k.csv')\n",
    "load_session('assign3data10k','file:///data_10k.csv')\n",
    "load_session('assign3data20k','file:///data_20k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
