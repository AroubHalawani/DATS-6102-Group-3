Group 3
Qifan Gu, Brian Gulko, Aroub Halawani
DATS-6102-11
Fall 2023
Professor Hazim Shatnawi

This project uses SQL and MongoDB to store data from the csv file 'gsearch_jobs_300k.csv'. This is the link to download the files, in case it is too large to submit to BlackBoard: https://drive.google.com/file/d/1S6709rcHgVAAZn3hefVKX_tfL6HuJZZQ/view?usp=sharing


SQL:
For SQL XAMPP must be installed and running. From there, go to PHPMyAdmin and then SQL. Then run the code in the 'SQL_Database_Creation.txt' file to create the databases, tables, and import the data. To do this, the 'gsearch_jobs_300k.csv' file must be placed in the 'jobs3' and 'jobs4' subfolders after the databases are created. The file path should look something like this: 'C:\xampp\mysql\data\jobs3'. Alternatively, you can alter the code to specify a different file location for the dataset. 
NOTE: The 'gsearch_jobs_300k.csv' file is in the zip file 'gsearch_jobs_300k.zip'.
NOTE: Importing the data may take some time. If there appears to be an error for max_execution_time, fpr the file xampp\php\php.ini, modify the line:
max_execution_time = 600;


MongoDB:
Start MongoDBCompass, connect, and create a database (we called ours 'Jobs'). Then create a collection (we called ours 'job_posts2'). In that collection use the Add Data feature to import the data from the csv file.


Run the Queries:
Run the code in the python file Run_Queries.ipynb.
NOTE: Make sure that the libraries imported are installed before running the code.
WARNING: Running these queries can be very time consuming. You should only try to run one at a time. Since each query is run 30 times you can expect it to take 15+ minutes per query depending on your computer specs.

When writing the results to an .xlsx file, we recommend that you first create the file in the folder where your notebook is, and with the name of your file_name. We used 'Query_Results_for_Submission.xlsx'
You can double check the queries in the SQL_Queries.txt and Momgo_Queries.txt


Test and visualize the results:
Run the python file Visualization_and_Analysis.ipynb
This file uses the data from our results stored in Query_Results_for_Submission.xslx.
NOTE: As each version of results take about 9 to 10 hours, Query_Results_for_Submission.xslx may not be the final version when we find some mistakes and rerun the Run_Queries.ipynb code after the submission. 
